{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZxBZ8wjAPQz1"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_download_id_and_size_in_bytes(trajectory_id):\n",
    "    polygon = trajectories[trajectories['trajectoryid'] == trajectory_id].geometry.values[0]\n",
    "    coords = [[x, y] for x, y in polygon.exterior.coords]\n",
    "    url = \"https://mein.wien.gv.at/geodownload-backend/app/register\"\n",
    "    payload = {\n",
    "        \"data\": {\n",
    "            \"coords\": coords,\n",
    "            \"dataset\": \"KAPPAZUNDER 2020\",\n",
    "            \"option\": 2\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    items = response.json().get('items')\n",
    "    return items.get('confirmation'), items.get('size') * 1024 * 1024\n",
    "\n",
    "\n",
    "def request_confirm_email(download_id):\n",
    "    with requests.Session() as session:\n",
    "        session.get(f\"https://mein.wien.gv.at/geodownload-ui/confirm/{download_id}\", headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        })\n",
    "        response = session.patch(f\"https://mein.wien.gv.at/geodownload-backend/app/confirm/{download_id}\", json={\"mail\": EMAIL_ADDRESS}, headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "            \"Accept\": \"application/json, text/plain, */*\",\n",
    "            \"Origin\": \"https://mein.wien.gv.at\",\n",
    "            \"Referer\": \"https://mein.wien.gv.at/\",\n",
    "        })\n",
    "        response.raise_for_status()\n",
    "\n",
    "\n",
    "def confirm_email():\n",
    "    url = \"https://mein.wien.gv.at/geodownload-backend/app/mail/2d4bf8b8-88cb-4c9c-b29b-bf2f5ef50c8f\"\n",
    "    response = requests.patch(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "\n",
    "def download(download_id, size):\n",
    "    url = f\"https://www.wien.gv.at/ogdgeodata/download/{download_id}.tar\"\n",
    "    headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\" }\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        block_size = 8*1024\n",
    "        progress_bar = tqdm(total=size, unit='iB', unit_scale=True, desc=f\"Downloading {download_id}.tar\")\n",
    "        with open(download_id + \".tar\", \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=block_size):\n",
    "                progress_bar.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "        progress_bar.close()\n",
    "\n",
    "\n",
    "def extract_and_remove_tar(download_id):\n",
    "    tar_path = download_id + \".tar\"\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        tar.extractall(path=download_id)\n",
    "    os.remove(tar_path)\n",
    "\n",
    "\n",
    "def get_trajectory_dir_paths(download_id, trajectory_id):\n",
    "    los_dirs = [f for f in os.listdir(download_id)]\n",
    "    possible_trajectory_dir_paths = [os.path.join(download_id, los_dir, \"Bild-Rohdaten\", f\"Trajektorie_{trajectory_id}\") for los_dir in los_dirs]\n",
    "    return [d for d in possible_trajectory_dir_paths if os.path.isdir(d)]\n",
    "\n",
    "\n",
    "def prune_downloaded_data(download_id, trajectory_dir_paths_to_keep):\n",
    "    for los_dir in os.listdir(download_id):\n",
    "        bild_rohdaten_dir_path = os.path.join(download_id, los_dir, \"Bild-Rohdaten\")\n",
    "        for trajectory_dir in os.listdir(bild_rohdaten_dir_path):\n",
    "            trajectory_dir_path = os.path.join(bild_rohdaten_dir_path, trajectory_dir)\n",
    "            if os.path.isdir(trajectory_dir_path) and trajectory_dir_path not in trajectory_dir_paths_to_keep:\n",
    "                shutil.rmtree(trajectory_dir_path)\n",
    "\n",
    "\n",
    "def remove_top_and_bottom_facing_images(trajectory_dir_paths):\n",
    "    for trajectory_dir_path in trajectory_dir_paths:\n",
    "        for name in os.listdir(trajectory_dir_path):\n",
    "            if name.endswith((\"0\", \"5\")):\n",
    "                shutil.rmtree(os.path.join(trajectory_dir_path, name))\n",
    "\n",
    "\n",
    "def set_exif_tags(trajectory_dir_paths):\n",
    "    def deg_to_dms_rational(deg_float):\n",
    "        \"\"\"\n",
    "        Convert decimal degrees to EXIF DMS rational format.\n",
    "        \"\"\"\n",
    "        deg_abs = abs(deg_float)\n",
    "        deg = int(deg_abs)\n",
    "        min_float = (deg_abs - deg) * 60\n",
    "        min_ = int(min_float)\n",
    "        sec = round((min_float - min_) * 60 * 10000)\n",
    "        return ((deg, 1), (min_, 1), (sec, 10000))\n",
    "\n",
    "    file_paths = []\n",
    "    for trajectory_dir_path in trajectory_dir_paths:\n",
    "        for sensor_dir in os.listdir(trajectory_dir_path):\n",
    "            sensor_dir_path = os.path.join(trajectory_dir_path, sensor_dir)\n",
    "            sensor_dir_content_paths = [os.path.join(sensor_dir_path, file) for file in os.listdir(sensor_dir_path)]\n",
    "            file_paths.extend([file for file in sensor_dir_content_paths if os.path.isfile(file)])\n",
    "\n",
    "    for img_path in tqdm(file_paths, desc=\"Tagging images\"):\n",
    "        file = os.path.basename(img_path)\n",
    "        row = points.loc[file]\n",
    "        if row.empty:\n",
    "            print(f\"⚠️ No metadata found for {file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Load existing EXIF or create new\n",
    "        exif_dict = piexif.load(img.info.get(\"exif\", b\"\"))\n",
    "\n",
    "        # GPS\n",
    "        exif_dict[\"GPS\"] = {\n",
    "            piexif.GPSIFD.GPSLatitudeRef: b\"N\",\n",
    "            piexif.GPSIFD.GPSLatitude: deg_to_dms_rational(row[\"lat\"]),\n",
    "            piexif.GPSIFD.GPSLongitudeRef: b\"E\",\n",
    "            piexif.GPSIFD.GPSLongitude: deg_to_dms_rational(row[\"lon\"]),\n",
    "        }\n",
    "\n",
    "        # DateTimeOriginal\n",
    "        exif_dict[\"Exif\"][piexif.ExifIFD.DateTimeOriginal] = row[\"epoch\"].strftime(\"%Y:%m:%d %H:%M:%S\").encode(\"utf-8\")\n",
    "\n",
    "        # Insert EXIF back into image\n",
    "        exif_bytes = piexif.dump(exif_dict)\n",
    "        piexif.insert(exif_bytes, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mFeWJUJDPTTE"
   },
   "outputs": [],
   "source": [
    "import imaplib\n",
    "import email\n",
    "from email.header import decode_header\n",
    "import re\n",
    "\n",
    "class ReadyToDownloadChecker:\n",
    "    # Exact URL pattern with GUID\n",
    "    GUID_REGEX = re.compile(\n",
    "        r'https://www\\.wien\\.gv\\.at/ogdgeodata/download/'\n",
    "        r'([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})\\.tar'\n",
    "    )\n",
    "\n",
    "    def __init__(self, email_address, app_password, email_subject_filter):\n",
    "        self.email_address = email_address\n",
    "        self.app_password = app_password\n",
    "        self.subject_filter = email_subject_filter\n",
    "        self.imap = None\n",
    "        self.emails = []  # List of (subject, body)\n",
    "        self._connect()\n",
    "        self._fetch_emails_by_subject()\n",
    "\n",
    "    def _connect(self):\n",
    "        if self.imap:\n",
    "            try:\n",
    "                self.imap.logout()\n",
    "            except:\n",
    "                pass\n",
    "        self.imap = imaplib.IMAP4_SSL(\"imap.gmail.com\")\n",
    "        self.imap.login(self.email_address, self.app_password)\n",
    "        self.imap.select(\"inbox\")\n",
    "\n",
    "    def _fetch_emails_by_subject(self):\n",
    "        search_criterion = f'(SUBJECT \"{self.subject_filter}\")'\n",
    "        status, messages = self.imap.search(None, search_criterion)\n",
    "        if status != \"OK\":\n",
    "            return\n",
    "        for num in messages[0].split():\n",
    "            self._fetch_email(num)\n",
    "\n",
    "    def _fetch_email(self, num):\n",
    "        status, msg_data = self.imap.fetch(num, \"(RFC822)\")\n",
    "        if status != \"OK\":\n",
    "            return\n",
    "        msg = email.message_from_bytes(msg_data[0][1])\n",
    "        subject = decode_header(msg.get(\"Subject\") or \"\")[0][0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(errors=\"ignore\")\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == \"text/plain\":\n",
    "                    try:\n",
    "                        body += part.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "                    except:\n",
    "                        pass\n",
    "        else:\n",
    "            try:\n",
    "                body = msg.get_payload(decode=True).decode(errors=\"ignore\")\n",
    "            except:\n",
    "                pass\n",
    "        self.emails.append((subject, body))\n",
    "\n",
    "    def refresh(self):\n",
    "        \"\"\"Fetch only unseen emails with matching subject\"\"\"\n",
    "        try:\n",
    "            self._connect()\n",
    "            search_criterion = f'(UNSEEN SUBJECT \"{self.subject_filter}\")'\n",
    "            status, messages = self.imap.search(None, search_criterion)\n",
    "            if status == \"OK\":\n",
    "                for num in messages[0].split():\n",
    "                    self._fetch_email(num)\n",
    "        except Exception as e:\n",
    "            print(\"Error refreshing mail:\", e)\n",
    "\n",
    "    def get_ids(self):\n",
    "        \"\"\"Return a deduplicated list of GUIDs from cached emails\"\"\"\n",
    "        guids = set()\n",
    "        for _, body in self.emails:\n",
    "            matches = self.GUID_REGEX.findall(body)\n",
    "            guids.update(matches)\n",
    "        return list(guids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 903266,
     "status": "error",
     "timestamp": 1762724174120,
     "user": {
      "displayName": "Elias Gander",
      "userId": "00320090336903503101"
     },
     "user_tz": -60
    },
    "id": "DuxL3k3-PU79",
    "outputId": "e8e4310b-638c-4b0b-8866-5c96fc911559"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m points = gpd.read_file(\u001b[33m\"\u001b[39m\u001b[33mpoints.gpkg\u001b[39m\u001b[33m\"\u001b[39m, layer=\u001b[33m\"\u001b[39m\u001b[33mkappazunder_image_punkte__ogdwienkappazunderimagepogd\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m trajectories_path = \u001b[33m\"\u001b[39m\u001b[33mtrajectories.gpkg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m trajectories = \u001b[43mgpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectories_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m points = points.set_index(\u001b[33m\"\u001b[39m\u001b[33mimage_name\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IS_DEBUG:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/coding/anderes/kappazunder-to-mapillary/venv/lib/python3.13/site-packages/geopandas/io/file.py:316\u001b[39m, in \u001b[36m_read_file\u001b[39m\u001b[34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m             filename = response.read()\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.api.types.is_file_like(filename):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/coding/anderes/kappazunder-to-mapillary/venv/lib/python3.13/site-packages/geopandas/io/file.py:576\u001b[39m, in \u001b[36m_read_file_pyogrio\u001b[39m\u001b[34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m     warnings.warn(\n\u001b[32m    568\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mignore_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keywords are deprecated, and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future release. You can use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    573\u001b[39m     )\n\u001b[32m    574\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/coding/anderes/kappazunder-to-mapillary/venv/lib/python3.13/site-packages/pyogrio/geopandas.py:275\u001b[39m, in \u001b[36mread_dataframe\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[32m    274\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdatetime_as_string\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m result = \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/coding/anderes/kappazunder-to-mapillary/venv/lib/python3.13/site-packages/pyogrio/raw.py:198\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dataset_kwargs = _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "import piexif\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from time import sleep\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "\n",
    "MAPILLARY_USER = \"eliasgander\"\n",
    "MAPILLARY_EMAIL = \"daring.64tum@icloud.com\"\n",
    "MAPILLARY_PASSWORD = \"cesjuD-6tyjmo-maqgif\"\n",
    "EMAIL_ADDRESS = \"tomturbo657@gmail.com\"\n",
    "GMAIL_APP_PASSWORD = \"kruf aahg aiuc iwtr\"\n",
    "DOWNLOAD_READY_SUBJECT = \"Download-Link zu Ihren Geodaten\"\n",
    "IS_DEBUG = True\n",
    "\n",
    "points = gpd.read_file(\"points.gpkg\", layer=\"kappazunder_image_punkte__ogdwienkappazunderimagepogd\")\n",
    "trajectories_path = \"trajectories.gpkg\"\n",
    "trajectories = gpd.read_file(trajectories_path)\n",
    "points = points.set_index(\"image_name\")\n",
    "if IS_DEBUG:\n",
    "  trajectories = trajectories[trajectories['trajectoryid'].isin(['17720', '16101', '16471'])]\n",
    "  trajectories.loc[trajectories['trajectoryid'] == '17720', ['download_id', 'download_bytes', 'download_expires_at']] = ['5276d431-a054-4a84-a38c-6dfbccefdef0', 1403*1024*1024, pd.Timestamp.now() + timedelta(days=7)]\n",
    "  trajectories.loc[trajectories['trajectoryid'] == '16101', ['download_id', 'download_bytes', 'download_expires_at']] = ['56a27033-35ed-4c3c-ba14-704cc256efac', 668*1024*1024, pd.Timestamp.now() + timedelta(days=7)]\n",
    "  trajectories.loc[trajectories['trajectoryid'] == '16471', ['download_id', 'download_bytes', 'download_expires_at']] = ['e4a3d58b-2c58-4991-8e98-ae7b635d25cf', 720*1024*1024, pd.Timestamp.now() + timedelta(days=7)]\n",
    "\n",
    "!mapillary_tools authenticate --user_name {MAPILLARY_USER} --user_email {MAPILLARY_EMAIL} --user_password {MAPILLARY_PASSWORD}\n",
    "\n",
    "ready_to_download = ReadyToDownloadChecker(EMAIL_ADDRESS, GMAIL_APP_PASSWORD, DOWNLOAD_READY_SUBJECT)\n",
    "\n",
    "def save_trajectories():\n",
    "  if not IS_DEBUG:\n",
    "    trajectories.to_file(trajectories_path, layer=\"kappazunder_image_punkte__ogdwienkappazunderimagepogd\", driver=\"GPKG\")\n",
    "\n",
    "sensors_completed_column_names = [f\"is_sensor{i}_completed\" for i in range(1, 5)]\n",
    "\n",
    "while not trajectories[sensors_completed_column_names].to_numpy().all():\n",
    "    print(f\"Number of uncompleted trajectories: {trajectories[~trajectories[sensors_completed_column_names].to_numpy().all(axis=1)].shape[0]}\")\n",
    "\n",
    "    expiring_trajectories = trajectories[trajectories['download_expires_at'].notna() & (trajectories['download_expires_at'] < pd.Timestamp.now() + timedelta(hours=5))]\n",
    "    if not expiring_trajectories.empty:\n",
    "        print(f\"Resetting expiring trajectories with IDs: {expiring_trajectories['trajectoryid'].tolist()}\")\n",
    "        trajectories.loc[expiring_trajectories.index, ['download_id', 'download_bytes', 'download_expires_at']] = [None, None, None]\n",
    "\n",
    "    ready_to_download.refresh()\n",
    "    trajectories_to_download = trajectories[trajectories['download_id'].isin(ready_to_download.get_ids())]\n",
    "    if len(trajectories_to_download) <= 5:\n",
    "        print(f\"Only {len(trajectories_to_download)} downloadable trajectories left\")\n",
    "        trajectories_to_prepare = trajectories[trajectories['download_id'].isna()]\n",
    "        if trajectories_to_prepare.empty:\n",
    "            print(\"No trajectories left to prepare\")\n",
    "        else:\n",
    "            trajectories_to_prepare = trajectories_to_prepare.sample(min(10, len(trajectories)))\n",
    "            print(f\"Preparing {len(trajectories_to_prepare)} trajectories with ids: {trajectories_to_prepare['trajectoryid'].tolist()}\")\n",
    "            for index, trajectory in trajectories_to_prepare.iterrows():\n",
    "                trajectory_id = trajectory['trajectoryid']\n",
    "                try:\n",
    "                    download_id, size = get_download_id_and_size(trajectory_id)\n",
    "                    request_confirm_email(download_id)\n",
    "                    sleep(60)\n",
    "                    confirm_email()\n",
    "                    trajectories.loc[trajectories['trajectoryid'] == trajectory_id, ['download_id', 'download_bytes', 'download_expires_at']] = [download_id, size, pd.Timestamp.now() + timedelta(days=7)]\n",
    "                    save_trajectories()\n",
    "                    print(f\"Successfully prepared trajectoryid {trajectory_id} with downloadid {download_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error preparing trajectoryid {trajectory_id} with downloadid {download_id}: {e}\")\n",
    "\n",
    "    if trajectories_to_download.empty:\n",
    "        print(\"No trajectories ready for download. Sleeping five minutes.\")\n",
    "        sleep(300)\n",
    "        continue\n",
    "\n",
    "    trajectory_to_download = trajectories_to_download.sort_values('download_expires_at').iloc[0]\n",
    "    trajectory_id = trajectory_to_download['trajectoryid']\n",
    "    download_id = trajectory_to_download['download_id']\n",
    "    if not os.path.isdir(download_id):\n",
    "      try:\n",
    "            download(download_id, trajectory_to_download['download_bytes'])\n",
    "      except HTTPError as e:\n",
    "          if e.code == 404:\n",
    "            print(f\"Resetting downloadid {download_id} of trajectory {trajectory_id} because 404 error: {e}\")\n",
    "            trajectories.loc[trajectories['trajectoryid'] == trajectory_id, ['download_id', 'download_bytes', 'download_expires_at']] = [None, None, None]\n",
    "            save_trajectories()\n",
    "          else:\n",
    "            print(f\"Sleeping for five minutes because download of trajectory {trajectory_id} with downloadid {download_id} failed with message: {e}\")\n",
    "            sleep(300)\n",
    "          continue\n",
    "      extract_and_remove_tar(download_id)\n",
    "      \n",
    "    trajectory_dir_paths = get_trajectory_dir_paths(download_id, trajectory_id.split('_', 1)[0])\n",
    "    prune_downloaded_data(download_id, trajectory_dir_paths)\n",
    "    remove_top_and_bottom_facing_images(trajectory_dir_paths)\n",
    "    set_exif_tags(trajectory_dir_paths)\n",
    "    for i in range(1, 5):\n",
    "        if trajectories[trajectories['trajectoryid'] == trajectory_id][f'is_sensor{i}_completed'].iloc[0]:\n",
    "          continue\n",
    "        cmd = f\"\"\"\n",
    "        mapillary_tools process_and_upload \\\n",
    "            --overwrite_all_EXIF_tags \\\n",
    "            --device_make Teledyne \\\n",
    "            --device_model Ladybug6 \\\n",
    "            --offset_angle {(i - 1) * 90} \\\n",
    "            --interpolate_directions \\\n",
    "            --user_name {MAPILLARY_USER} \\\n",
    "            --noresume \\\n",
    "            {download_id}/*/Bild-Rohdaten/Trajektorie_{trajectory_id}/Sensor_*{i}/\n",
    "        \"\"\"\n",
    "        !{cmd}\n",
    "        trajectories.loc[trajectories['trajectoryid'] == trajectory_id, f'is_sensor{i}_completed'] = True\n",
    "        save_trajectories()\n",
    "    #shutil.rmtree(download_id)\n",
    "\n",
    "\n",
    "print(\"All trajectories completed.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOx2YobyJfj49KILurLjqIR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
